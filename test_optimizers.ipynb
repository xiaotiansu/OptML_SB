{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a1c8e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.functional import F\n",
    "from torchvision.transforms import functional\n",
    "import random\n",
    "import torch.optim as optim\n",
    "from tqdm.notebook import tqdm\n",
    "import torchvision\n",
    "from time import time\n",
    "import torch.optim.lr_scheduler as S\n",
    "import math\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7af0fa2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7f7556fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda'\n",
    "\n",
    "test_set = torchvision.datasets.MNIST(root = 'data/', train = False, download = True)\n",
    "test_input = test_set.data.view(-1, 1, 28, 28).float().to(device)\n",
    "test_targets = test_set.targets.to(device)\n",
    "\n",
    "mu, std = test_input.mean(), test_input.std()\n",
    "test_input.sub_(mu).div_(std)\n",
    "\n",
    "train_set = torchvision.datasets.MNIST(root = 'data/', train = True, download = True)\n",
    "train_input = train_set.data.view(-1, 1, 28, 28).float()\n",
    "train_targets = train_set.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6dee1c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mLeNet(nn.Module):\n",
    "    def __init__(self, use_bn=False):\n",
    "        super(mLeNet, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5, padding = 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        last_channel = 16\n",
    "        self.conv3 = nn.Conv2d(16, last_channel, 2)\n",
    "        self.use_bn = use_bn\n",
    "        if self.use_bn:\n",
    "            self.conv1_bn = nn.BatchNorm2d(6)\n",
    "            self.conv2_bn = nn.BatchNorm2d(16)\n",
    "            self.conv3_bn = nn.BatchNorm2d(last_channel)\n",
    "\n",
    "        self.fc3 = nn.Linear(last_channel, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_bn:\n",
    "            x = F.max_pool2d(F.relu(self.conv1_bn(self.conv1(x))), 2)\n",
    "            x = F.max_pool2d(F.relu(self.conv2_bn(self.conv2(x))), 2)\n",
    "            x = F.max_pool2d(F.relu(self.conv3_bn(self.conv3(x))), 2)\n",
    "        else:\n",
    "            x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
    "            x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "            x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
    "        x = F.adaptive_avg_pool2d(x,1)\n",
    "        x = torch.flatten(x, 1)\n",
    "        #x = F.relu(self.fc1(x))\n",
    "        #x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "db1cf958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(use_bn = False, lr = 0.005, optimize_method = torch.optim.Adam, seed = 0):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    device = 'cuda'\n",
    "    nb_epochs, batch_size = 3000, 32\n",
    "\n",
    "    model = mLeNet(use_bn = use_bn)\n",
    "    model.to(device)\n",
    "    optimizer = optimize_method(model.parameters(), lr = lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = S.StepLR(optimizer, step_size=200, gamma=1)\n",
    "\n",
    "    train_len, attack_len = 512, 0\n",
    "    lbd = 0\n",
    "\n",
    "    test_acc = []\n",
    "    train_acc = []\n",
    "    l_list = []\n",
    "\n",
    "    criterion.to(device)\n",
    "\n",
    "    train_x, train_y = train_input[:train_len].to(device), train_targets[:train_len].to(device)\n",
    "    mu, std = train_x.mean(), train_x.std()\n",
    "    train_x.sub_(mu).div_(std)\n",
    "\n",
    "    attack_x, attack_y = train_input[train_len:train_len + attack_len].to(device), train_targets[train_len:train_len + attack_len].to(device)\n",
    "    mu, std = attack_x.mean(), attack_x.std()\n",
    "    attack_x.sub_(mu).div_(std)\n",
    "\n",
    "    mylist = list(range(10))\n",
    "    for i in range(attack_len):\n",
    "        n = mylist[:]\n",
    "        n.remove(attack_y[i])\n",
    "        attack_y[i] = random.choice(n)\n",
    "\n",
    "\n",
    "    train_batches = math.ceil(train_len/batch_size)\n",
    "\n",
    "    for e in tqdm(range(nb_epochs)):\n",
    "        ite = 0\n",
    "        for input, targets in zip(train_x.split(batch_size) + attack_x.split(batch_size),train_y.split(batch_size) + attack_y.split(batch_size)):\n",
    "        \n",
    "        #for input, targets in zip(train_x.split(batch_size),train_y.split(batch_size)):\n",
    "            output = model(input)\n",
    "            ite += 1\n",
    "            if ite<=train_batches:\n",
    "                loss = criterion(output, targets)\n",
    "            else:\n",
    "                loss = lbd*criterion(output, targets)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        scheduler.step()\n",
    "        with torch.no_grad():\n",
    "            out = model(train_x)\n",
    "            _, predicted_classes = out.max(1)\n",
    "            _, predicted_classes_test = model(test_input).max(1)\n",
    "\n",
    "            l = criterion(out, train_y).item()\n",
    "            test_a = (predicted_classes_test == test_targets).to(float).mean().item()\n",
    "            train_a = (predicted_classes == train_y).to(float).mean().item()\n",
    "\n",
    "            l_list.append(l)\n",
    "            test_acc.append(test_a)\n",
    "            train_acc.append(train_a)\n",
    "            \n",
    "            if (e>=300) and (all(i >= 2 for i in l_list[-10:])):\n",
    "                return model,\"diverge\"\n",
    "                break\n",
    "            \n",
    "            print(\"epoch: %i, loss: %.4f, train_acc: %.4f, test_acc: %.4f\" %(e+1,l,train_a,test_a))\n",
    "            stats = [e+1,l,train_a,test_a]\n",
    "            if l <= 0.001:\n",
    "                return model,stats\n",
    "                break\n",
    "    return model,stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "233e68d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def H_fro_approx(model, use_bn = False, seed = 0):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "    device = 'cuda'\n",
    "    train_len = 512\n",
    "\n",
    "    train_x, train_y = train_input[:train_len].to(device), train_targets[:train_len].to(device)\n",
    "    mu, std = train_x.mean(), train_x.std()\n",
    "    train_x.sub_(mu).div_(std)\n",
    "    m_up = mLeNet(use_bn = use_bn).to(device)\n",
    "    m_down = mLeNet(use_bn = use_bn).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    criterion.to(device)\n",
    "    eps = 1e-5\n",
    "    M=100\n",
    "    diffs = torch.zeros(M)\n",
    "    for i in range(M):\n",
    "        m_up.zero_grad()\n",
    "        m_down.zero_grad()\n",
    "        for po,p_up,p_down in zip(model.parameters(),m_up.parameters(),m_down.parameters()):\n",
    "            temp = torch.normal(0,1,size=po.shape).to(device)\n",
    "            p_up.data = po + eps*temp\n",
    "            p_down.data = po - eps*temp\n",
    "            #print(p_up.shape,p_down.shape)\n",
    "\n",
    "        loss_up = criterion(m_up(train_x), train_y)\n",
    "        loss_up.backward()\n",
    "\n",
    "        loss_down = criterion(m_down(train_x), train_y)\n",
    "        loss_down.backward()\n",
    "\n",
    "\n",
    "        grad_up = []\n",
    "        grad_down = []\n",
    "\n",
    "        nparams = 0\n",
    "        for p_up,p_down in zip(m_up.parameters(),m_down.parameters()):\n",
    "            grad_up.append(p_up.grad.view(-1).data)\n",
    "            grad_down.append(p_down.grad.view(-1).data)\n",
    "            \n",
    "        diffs[i] = ((torch.concat(grad_up)-torch.concat(grad_down))**2).sum()\n",
    "\n",
    "    return (diffs.sum()/(4*M*eps*eps)).sqrt().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b03c1934",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.optim.adagrad.Adagrad'> 0.01 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa90a466bc84f70b2279e6e403d1670",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss: 1.7476, train_acc: 0.7051, test_acc: 0.5773\n",
      "epoch: 2, loss: 1.5069, train_acc: 0.8203, test_acc: 0.6807\n",
      "epoch: 3, loss: 1.3289, train_acc: 0.8574, test_acc: 0.7233\n",
      "epoch: 4, loss: 1.1834, train_acc: 0.8984, test_acc: 0.7478\n",
      "epoch: 5, loss: 1.0636, train_acc: 0.9102, test_acc: 0.7679\n",
      "epoch: 6, loss: 0.9629, train_acc: 0.9180, test_acc: 0.7855\n",
      "epoch: 7, loss: 0.8817, train_acc: 0.9316, test_acc: 0.7974\n",
      "epoch: 8, loss: 0.8108, train_acc: 0.9492, test_acc: 0.8061\n",
      "epoch: 9, loss: 0.7510, train_acc: 0.9531, test_acc: 0.8151\n",
      "epoch: 10, loss: 0.7000, train_acc: 0.9551, test_acc: 0.8229\n",
      "epoch: 11, loss: 0.6542, train_acc: 0.9590, test_acc: 0.8274\n",
      "epoch: 12, loss: 0.6134, train_acc: 0.9609, test_acc: 0.8329\n",
      "epoch: 13, loss: 0.5764, train_acc: 0.9648, test_acc: 0.8365\n",
      "epoch: 14, loss: 0.5451, train_acc: 0.9648, test_acc: 0.8399\n",
      "epoch: 15, loss: 0.5148, train_acc: 0.9688, test_acc: 0.8422\n",
      "epoch: 16, loss: 0.4883, train_acc: 0.9727, test_acc: 0.8437\n",
      "epoch: 17, loss: 0.4632, train_acc: 0.9746, test_acc: 0.8470\n",
      "epoch: 18, loss: 0.4400, train_acc: 0.9746, test_acc: 0.8495\n",
      "epoch: 19, loss: 0.4196, train_acc: 0.9766, test_acc: 0.8497\n",
      "epoch: 20, loss: 0.4007, train_acc: 0.9805, test_acc: 0.8520\n",
      "epoch: 21, loss: 0.3836, train_acc: 0.9805, test_acc: 0.8541\n",
      "epoch: 22, loss: 0.3664, train_acc: 0.9805, test_acc: 0.8551\n",
      "epoch: 23, loss: 0.3518, train_acc: 0.9824, test_acc: 0.8553\n",
      "epoch: 24, loss: 0.3367, train_acc: 0.9824, test_acc: 0.8569\n",
      "epoch: 25, loss: 0.3243, train_acc: 0.9844, test_acc: 0.8570\n",
      "epoch: 26, loss: 0.3112, train_acc: 0.9844, test_acc: 0.8579\n",
      "epoch: 27, loss: 0.2990, train_acc: 0.9844, test_acc: 0.8588\n",
      "epoch: 28, loss: 0.2876, train_acc: 0.9863, test_acc: 0.8591\n",
      "epoch: 29, loss: 0.2766, train_acc: 0.9863, test_acc: 0.8609\n",
      "epoch: 30, loss: 0.2670, train_acc: 0.9863, test_acc: 0.8617\n",
      "epoch: 31, loss: 0.2572, train_acc: 0.9883, test_acc: 0.8625\n",
      "epoch: 32, loss: 0.2481, train_acc: 0.9902, test_acc: 0.8632\n",
      "epoch: 33, loss: 0.2404, train_acc: 0.9922, test_acc: 0.8632\n",
      "epoch: 34, loss: 0.2318, train_acc: 0.9941, test_acc: 0.8641\n",
      "epoch: 35, loss: 0.2243, train_acc: 0.9961, test_acc: 0.8640\n",
      "epoch: 36, loss: 0.2167, train_acc: 0.9980, test_acc: 0.8652\n",
      "epoch: 37, loss: 0.2102, train_acc: 0.9980, test_acc: 0.8663\n",
      "epoch: 38, loss: 0.2038, train_acc: 0.9980, test_acc: 0.8655\n",
      "epoch: 39, loss: 0.1971, train_acc: 0.9980, test_acc: 0.8671\n",
      "epoch: 40, loss: 0.1915, train_acc: 0.9980, test_acc: 0.8662\n",
      "epoch: 41, loss: 0.1857, train_acc: 0.9980, test_acc: 0.8668\n",
      "epoch: 42, loss: 0.1805, train_acc: 0.9980, test_acc: 0.8670\n",
      "epoch: 43, loss: 0.1753, train_acc: 0.9980, test_acc: 0.8676\n",
      "epoch: 44, loss: 0.1704, train_acc: 0.9980, test_acc: 0.8677\n",
      "epoch: 45, loss: 0.1658, train_acc: 0.9980, test_acc: 0.8684\n",
      "epoch: 46, loss: 0.1613, train_acc: 1.0000, test_acc: 0.8676\n",
      "epoch: 47, loss: 0.1571, train_acc: 1.0000, test_acc: 0.8673\n",
      "epoch: 48, loss: 0.1530, train_acc: 1.0000, test_acc: 0.8673\n",
      "epoch: 49, loss: 0.1491, train_acc: 1.0000, test_acc: 0.8675\n",
      "epoch: 50, loss: 0.1455, train_acc: 1.0000, test_acc: 0.8673\n",
      "epoch: 51, loss: 0.1419, train_acc: 1.0000, test_acc: 0.8671\n",
      "epoch: 52, loss: 0.1387, train_acc: 1.0000, test_acc: 0.8680\n",
      "epoch: 53, loss: 0.1353, train_acc: 1.0000, test_acc: 0.8678\n",
      "epoch: 54, loss: 0.1320, train_acc: 1.0000, test_acc: 0.8679\n",
      "epoch: 55, loss: 0.1291, train_acc: 1.0000, test_acc: 0.8679\n",
      "epoch: 56, loss: 0.1262, train_acc: 1.0000, test_acc: 0.8680\n",
      "epoch: 57, loss: 0.1234, train_acc: 1.0000, test_acc: 0.8681\n",
      "epoch: 58, loss: 0.1205, train_acc: 1.0000, test_acc: 0.8678\n",
      "epoch: 59, loss: 0.1179, train_acc: 1.0000, test_acc: 0.8682\n",
      "epoch: 60, loss: 0.1154, train_acc: 1.0000, test_acc: 0.8678\n",
      "epoch: 61, loss: 0.1129, train_acc: 1.0000, test_acc: 0.8683\n",
      "epoch: 62, loss: 0.1106, train_acc: 1.0000, test_acc: 0.8675\n",
      "epoch: 63, loss: 0.1082, train_acc: 1.0000, test_acc: 0.8680\n",
      "epoch: 64, loss: 0.1060, train_acc: 1.0000, test_acc: 0.8680\n",
      "epoch: 65, loss: 0.1039, train_acc: 1.0000, test_acc: 0.8681\n",
      "epoch: 66, loss: 0.1019, train_acc: 1.0000, test_acc: 0.8680\n",
      "epoch: 67, loss: 0.0999, train_acc: 1.0000, test_acc: 0.8679\n",
      "epoch: 68, loss: 0.0979, train_acc: 1.0000, test_acc: 0.8682\n",
      "epoch: 69, loss: 0.0961, train_acc: 1.0000, test_acc: 0.8679\n",
      "epoch: 70, loss: 0.0942, train_acc: 1.0000, test_acc: 0.8680\n",
      "epoch: 71, loss: 0.0925, train_acc: 1.0000, test_acc: 0.8681\n",
      "epoch: 72, loss: 0.0909, train_acc: 1.0000, test_acc: 0.8683\n",
      "epoch: 73, loss: 0.0891, train_acc: 1.0000, test_acc: 0.8678\n",
      "epoch: 74, loss: 0.0876, train_acc: 1.0000, test_acc: 0.8683\n",
      "epoch: 75, loss: 0.0861, train_acc: 1.0000, test_acc: 0.8679\n",
      "epoch: 76, loss: 0.0845, train_acc: 1.0000, test_acc: 0.8682\n",
      "epoch: 77, loss: 0.0831, train_acc: 1.0000, test_acc: 0.8683\n",
      "epoch: 78, loss: 0.0817, train_acc: 1.0000, test_acc: 0.8685\n",
      "epoch: 79, loss: 0.0803, train_acc: 1.0000, test_acc: 0.8683\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_82536/1641648120.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mll\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimize_method\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0mmy_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstats_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mll\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muse_bn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_bn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimize_method\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimize_method\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mHessians\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mll\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mH_fro_approx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_model\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muse_bn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muse_bn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHessians\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mii\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mll\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_82536/3155588777.py\u001b[0m in \u001b[0;36mtrain_model\u001b[1;34m(use_bn, lr, optimize_method, seed)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 58\u001b[1;33m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     59\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mscheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Bonan\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    306\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 307\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\Bonan\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 154\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_seed = 10\n",
    "stats_data = np.empty([3,num_seed],dtype=object)\n",
    "Hessians = np.empty([3,num_seed],dtype=object)\n",
    "optimizer_list = [torch.optim.Adagrad,torch.optim.SGD,torch.optim.Adam]\n",
    "lr = 0.01\n",
    "use_bn = True\n",
    "seed_list = list(range(num_seed))\n",
    "for ii, optimize_method in enumerate(optimizer_list):\n",
    "    for ll, seed in enumerate(seed_list):\n",
    "        print(optimize_method,lr,seed)\n",
    "        my_model,stats_data[ii,ll] = train_model(use_bn = use_bn, lr = lr, optimize_method = optimize_method, seed = seed)\n",
    "        Hessians[ii,ll] = H_fro_approx(my_model,use_bn = use_bn, seed = seed)\n",
    "        print(Hessians[ii,ll])\n",
    "        np.save(\"experiment_results/hessians_op.npy\",Hessians)\n",
    "        np.save(\"experiment_results/stats_data_op.npy\",stats_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "efd660a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Hessians = np.load(\"experiment_results/hessians_op.npy\", allow_pickle = True)\n",
    "stats_data = np.load(\"experiment_results/stats_data_op.npy\", allow_pickle = True)\n",
    "\n",
    "plt.scatter(Hessians[2], [x[-1] for x in stats_data[2]], label = \"Adam\", alpha=0.5)\n",
    "plt.scatter(Hessians[0], [x[-1] for x in stats_data[0]], label = \"Adagrad\", alpha=0.5)\n",
    "plt.scatter(Hessians[1], [x[-1] for x in stats_data[1]], label = \"SGD\", alpha=0.5)\n",
    "\n",
    "plt.gca().set_prop_cycle(None)\n",
    "\n",
    "plt.scatter(Hessians[2].mean(), np.mean([x[-1] for x in stats_data[2]]), marker = \"X\", s=100)\n",
    "plt.scatter(Hessians[0].mean(), np.mean([x[-1] for x in stats_data[0]]), marker = \"X\", s=100)\n",
    "plt.scatter(Hessians[1].mean(), np.mean([x[-1] for x in stats_data[1]]), marker = \"X\", s=100)\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel('Hessian norm')\n",
    "plt.ylabel('Test accuracy')\n",
    "plt.savefig(\"figures/optimizer.png\",dpi=200,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5cb630",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
